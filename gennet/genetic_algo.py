# # -*- coding: utf-8 -*-
# """Genetic_algo.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/13DedfOu67dtFMo4uxIZqowxf_7wjbC-P
# """

# from google.colab import drive
# drive.mount('/content/drive')

# #Changes to be done
# # 1. n_splits - make it 5 in getFitness function
# # 2. n_splits - make it 5 at last cell too

import pandas as pd
import os
import numpy as np
import random
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
# !pip install deap
from deap import creator, base, tools, algorithms
import sys
import pickle
from sklearn.metrics import confusion_matrix

# def avg(l):
#     """
#     Returns the average between list elements
#     """
#     return (sum(l)/float(len(l)))


# def getFitness(individual, X, y):
#     """
#     Feature subset fitness function
#     """

#     if(individual.count(0) != len(individual)):
#         # get index with value 0
#         cols = [index for index in range(
#             len(individual)) if individual[index] == 0]

#         # get features subset
#         X_parsed = X.drop(X.columns[cols], axis=1)
#         X_subset = pd.get_dummies(X_parsed)

#         # apply classification algorithm
#         clf = LogisticRegression(max_iter=5000, multi_class='multinomial')

#         return (avg(cross_val_score(clf, X_subset, y, cv=3)),)
#     else:
#         return(0,)

# def geneticAlgorithm(X, y, n_population, n_generation):
#     """
#     Deap global variables
#     Initialize variables to use eaSimple
#     """
#     # create individual
#     creator.create("FitnessMax", base.Fitness, weights=(1.0,))
#     creator.create("Individual", list, fitness=creator.FitnessMax)

#     # create toolbox
#     toolbox = base.Toolbox()
#     toolbox.register("attr_bool", random.randint, 0, 1)
#     toolbox.register("individual", tools.initRepeat,
#                      creator.Individual, toolbox.attr_bool, len(X.columns))
#     toolbox.register("population", tools.initRepeat, list,
#                      toolbox.individual)
#     toolbox.register("evaluate", getFitness, X=X, y=y)
#     toolbox.register("mate", tools.cxOnePoint)
#     toolbox.register("mutate", tools.mutFlipBit, indpb=0.05)
#     toolbox.register("select", tools.selTournament, tournsize=3)

#     # initialize parameters
#     pop = toolbox.population(n=n_population)
#     hof = tools.HallOfFame(n_population * n_generation)
#     stats = tools.Statistics(lambda ind: ind.fitness.values)
#     stats.register("avg", np.mean)
#     stats.register("min", np.min)
#     stats.register("max", np.max)

#     # genetic algorithm
#     pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2,
#                                    ngen=n_generation, stats=stats, halloffame=hof,
#                                    verbose=True)

#     # return hall of fame
#     return hof


# def bestIndividual(hof, X, y):
#     """
#     Get the best individual
#     """
#     maxAccurcy = 0.0
#     count = 0
#     for individual in hof:
#       # print(individual.fitness.values[0])
#       if(individual.fitness.values[0] > maxAccurcy):
#           maxAccurcy = individual.fitness.values
#           _individual = individual

#     _individualHeader = [list(X)[i] for i in range(
#         len(_individual)) if _individual[i] == 1]
#     return _individual.fitness.values, _individual, _individualHeader


# def getArguments():
#     """
#     Get argumments from command-line
#     If pass only dataframe path, pop and gen will be default
#     """
#     dfPath = sys.argv[1]
#     if(len(sys.argv) == 4):
#         pop = int(sys.argv[2])
#         gen = int(sys.argv[3])
#     else:
#         pop = 10
#         gen = 2
#     return dfPath, pop, gen

# # if __name__ == '__main__':
# #     # get dataframe path, population number and generation number from command-line argument
# #     dataframePath, n_pop, n_gen = getArguments()
# dataframePath_mob = "/content/drive/My Drive/COVID-19/feat_mob.csv"
# dataframePath_squ = "/content/drive/My Drive/COVID-19/feat_squ.csv"
# n_pop = 30
# n_gen = 6
# # read dataframe from csv
# df_mob = pd.read_csv(dataframePath_mob, sep=',')
# df_squ = pd.read_csv(dataframePath_squ, sep=',')

# # encode labels column to numbers
# le = LabelEncoder()
# le.fit(df_mob.iloc[:, -1])
# le.fit(df_squ.iloc[:, -1])
# y_mob = le.transform(df_mob.iloc[:, -1])
# y_squ = le.transform(df_squ.iloc[:, -1])
# X_mob = df_mob.iloc[:, :-1]
# X_squ = df_squ.iloc[:, :-1]

# # get accuracy with all features
# individual_mob = [1 for i in range(len(X_mob.columns))]
# individual_squ = [1 for i in range(len(X_squ.columns))]

# print("Accuracy with all mobilenet features: \t" + str(getFitness(individual_mob, X_mob, y_mob)) + "\n")
# print("Accuracy with all squeezenet features: \t" + str(getFitness(individual_squ, X_squ, y_squ)) + "\n")

# # apply genetic algorithm
# hof_mob = geneticAlgorithm(X_mob, y_mob, n_pop, n_gen)
# hof_squ = geneticAlgorithm(X_squ, y_squ, n_pop, n_gen)
# # select the best individual
# accuracy_mob, individual_mob, header_mob = bestIndividual(hof_mob, X_mob, y_mob)
# accuracy_squ, individual_squ, header_squ = bestIndividual(hof_squ, X_squ, y_squ)
# print('Best Accuracy for mobilenet: \t' + str(accuracy_mob))
# print('Number of Features in Subset: \t' + str(individual_mob.count(1)))
# print('Individual: \t\t' + str(individual_mob))
# print('Feature Subset\t: ' + str(header_mob))
# print('\n\ncreating a new classifier with the result')
# .03

# print('Best Accuracy for Squeezenet: \t' + str(accuracy_squ))
# print('Number of Features in Subset: \t' + str(individual_squ.count(1)))
# print('Individual: \t\t' + str(individual_squ))
# print('Feature Subset\t: ' + str(header_squ))
# print('\n\ncreating a new classifier with the result')
# .03
# read dataframe from csv one more time
# df_mob = pd.read_csv(dataframePath_mob, sep=',')
# df_squ = pd.read_csv(dataframePath_squ, sep=',')
# # with feature subset
# X_mob = df[header_mob]
# X_squ = df[header_squ]
# clf = svm.SVC( probability=True)
# clf = LogisticRegression()

# # scores_mob = cross_val_score(clf, X_mob, y_mob, cv=3)
# # scores_squ = cross_val_score(clf, X_squ, y_squ, cv=3)
# # print("Accuracy with Mobilenet Feature Subset: \t" + str(avg(scores_mob)) + "\n")
# # print("Accuracy with Squeezenet Feature Subset: \t" + str(avg(scores_squ)) + "\n")

def get_predictions(resource_dir, mob_features, squ_features):
    mob_header_file = os.path.join(resource_dir, 'mob_header.pickle')
    squ_header_file = os.path.join(resource_dir, 'squ_header.pickle')
    mob_classifier_file = os.path.join(resource_dir, 'mob_classifier.sav')
    squ_classifier_file = os.path.join(resource_dir, 'squ_classifier.sav')

    header_mob = []
    header_squ = []
    with open(mob_header_file, 'rb') as f:
        header_mob = pickle.load(f)
    with open(squ_header_file, 'rb') as f:
        header_squ = pickle.load(f)

    df_mob = pd.DataFrame(mob_features, columns=[str(i) for i in range(1,1001)])
    df_squ = pd.DataFrame(squ_features, columns=[str(i) for i in range(1,1001)])
    # with feature subset

    X_mob = df_mob[header_mob]
    X_squ = df_squ[header_squ]

    clf_mob = pickle.load(open(mob_classifier_file, 'rb'))
    clf_squ = pickle.load(open(squ_classifier_file, 'rb'))

    pred_prob_mob = clf_mob.predict_proba(X_mob)
    pred_prob_squ = clf_squ.predict_proba(X_squ)

    final_pred_prob = (pred_prob_squ + pred_prob_mob) / 2
    return final_pred_prob
# clf = svm.SVC( probability=True)
# # clf = LogisticRegression()

# scores_mob = cross_val_score(clf, X_mob, y_mob, cv=3)
# scores_squ = cross_val_score(clf, X_squ, y_squ, cv=3)
# print("Accuracy with Mobilenet Feature Subset: \t" + str(avg(scores_mob)) + "\n")
# print("Accuracy with Squeezenet Feature Subset: \t" + str(avg(scores_squ)) + "\n")

# clf_mob = svm.SVC( probability=True)
# clf_mob.fit(X_mob,y_mob)
# pickle.dump(clf_mob, open('/content/drive/My Drive/COVID-19/smo_resources/mob_classifier.sav', 'wb'))
# pred_prob_mob = clf_mob.predict_proba(X_mob)
# # results_mob = pd.DataFrame(data = pred_prob_mob)
# # results_mob.columns = pd.RangeIndex(0, len(results_mob.columns)) 
# # mob_pred = results_mob.idxmax(axis = 1) 
# # mob_pred
# pred_prob_mob

# clf_squ = svm.SVC( probability=True)
# clf_squ.fit(X_squ,y_squ)
# pickle.dump(clf_squ, open('/content/drive/My Drive/COVID-19/smo_resources/squ_classifier.sav', 'wb'))
# pred_prob_squ = clf_squ.predict_proba(X_squ)
# # results_squ = pd.DataFrame(data = pred_prob_squ)
# # results_squ.columns = pd.RangeIndex(0, len(results_squ.columns)) 
# # squ_pred = results_squ.idxmax(axis = 1) 
# # squ_pred
# pred_prob_squ

# mob_true = df_mob['1001']
# squ_true = df_mob['1001']
# print(accuracy_score(mob_true, mob_pred))
# print(accuracy_score(squ_true, squ_pred))

# final_pred_prob = (pred_prob_squ + pred_prob_mob) / 2

# final_pred_prob

# final_class_pred = np.argmax(final_pred_prob, axis=1)

# print(accuracy_score(squ_true, final_class_pred))
# print(confusion_matrix(squ_true, final_class_pred))

# confusion_matrix(mob_true, mob_pred)

# confusion_matrix(squ_true, squ_pred)

# mob_header_path = '/content/mob_header.pickle'
# pickle.dump(header_mob, open(mob_header_path, 'wb'))

# squ_header_path = '/content/squ_header.pickle'
# pickle.dump(header_squ, open(squ_header_path, 'wb'))

# # !cp '/content/smo_model_10000.sav' '/content/drive/My Drive/COVID-19'
# # !cp '/content/mob_header.pickle' '/content/drive/My Drive/COVID-19'
# # !cp '/content/squ_header.pickle' '/content/drive/My Drive/COVID-19'

